from pathlib import Path

## Data provided by PubChem group1
"""train"""
# data_dir = Path('/cvhci/temp/zihanchen/data/new_images_1M_group1')
# train_dir = data_dir / 'train_img' # training images path
# train_csv_dir = data_dir / 'train.csv'
# # train_modified contains information of the train/validation split in a pickle file format. I saved in pickle just for efficiency
# train_pickle_dir = data_dir /'train_modified.pkl'
#
# ### Data directory generated by us
# input_data_dir = data_dir / 'input_data' # output path
# base_file_name = 'seed_910_max100smiles'
### seed for train/val split
# random_seed = 910
# ### Reversed_token_file used to map numbers to string.
# reversed_token_map_dir = input_data_dir/ f'REVERSED_TOKENMAP_{base_file_name}.json'


## Data provided by PubChem group2
"""train"""
# #generate train_modified.pkl
# data_dir = Path('/cvhci/temp/zihanchen/data/new_images_1M_group2')
# train_dir = data_dir / 'train' # training images path
# train_csv_dir = data_dir / 'train.csv'
# # # train_modified contains information of the train/validation split in a pickle file format. I saved in pickle just for efficiency
# train_pickle_dir = data_dir /'train_modified.pkl'
# #
# # ### Data directory generated by us
# input_data_dir = data_dir / 'input_data' # output path
#
# random_seed = 123



"""test"""
#data_dir = Path('/cvhci/temp/zihanchen/data/DACON_SMILES_data/') #dataset which we created inputfile .json
# ### Data directory generated by us
# input_data_dir = data_dir / 'input_data' # output path
# base_file_name = 'seed_123_max75smiles'
# ### seed for train/val split
# random_seed = 123
# ### Reversed_token_file used to map numbers to string.
# reversed_token_map_dir = input_data_dir/ f'REVERSED_TOKENMAP_{base_file_name}.json'
#
# ###Test fromPubChem
# test_dir = '/cvhci/temp/zihanchen/data/testset_isomeric/test_img_20K/'
# #test_dir = '/cvhci/temp/zihanchen/data/new_images_1M_group1/train/'# image from pubchem less than 75
# sample_submission_dir = '/cvhci/temp/zihanchen/data/testset_isomeric/test_20K.csv'
# generate_submission_dir = 'test_20K_gray.csv'
# #generate_submission_dir = 'test_pubchem_75.csv'
# sample_submission_labels_dir = '/cvhci/temp/zihanchen/data/testset_isomeric/test_20K_labels.csv'

# ###submission test
test_dir = '/cvhci/temp/zihanchen/data/DACON_SMILES_data/test/'
sample_submission_dir = '/cvhci/temp/zihanchen/data/DACON_SMILES_data/sample_submission.csv'
generate_submission_dir = 'sample_submission.csv'

###RDKit test
# test_dir = '/cvhci/temp/zihanchen/data/RDkit_SMILES_gray/clear_img/'
# sample_submission_dir = '/cvhci/temp/zihanchen/data/RDkit_SMILES_gray/train_smiles.csv'
# generate_submission_dir = 'train_smiles_RDKit.csv'
# sample_submission_labels_dir = '/cvhci/temp/zihanchen/data/testset_isomeric/train_smiles_labels.csv'



#
# """train(DACON)"""
# data_dir = Path('/cvhci/temp/zihanchen/data/DACON_SMILES_data/')
# train_dir = data_dir / 'train' # training images path
# train_csv_dir = data_dir / 'train.csv'
# # train_modified contains information of the train/validation split in a pickle file format. I saved in pickle just for efficiency
# train_pickle_dir = data_dir /'train_modified.pkl'
#
# ### Data directory generated by us
# input_data_dir = data_dir / 'input_data' # output path
# base_file_name = 'seed_123_max75smiles'
#
# ### seed for train/val split
# random_seed = 123
#
# ### Reversed_token_file used to map numbers to string.
# reversed_token_map_dir = input_data_dir/ f'REVERSED_TOKENMAP_{base_file_name}.json'



## Multi-datasetï¼š
# lg dataset + 1M PubChem
"""train"""
data_dir = Path('/cvhci/temp/zihanchen/data/lg_PubChem1M_100')
data_dir_1 = Path('/cvhci/temp/zihanchen/data/DACON_SMILES_data') #DACON
data_dir_2 = Path('/cvhci/temp/zihanchen/data/new_images_1M_group1') #PubChem_1M_group1

train_dir_1 = data_dir_1 / 'train' # training images path #DACON
train_dir_2 = data_dir_2 / 'train' # training images path #DACON


# train_modified contains information of the train/validation split in a pickle file format. I saved in pickle just for efficiency
train_pickle_dir_1 = data_dir_1 /'train_modified.pkl'
train_pickle_dir_2 = data_dir_2 /'train_modified.pkl'

### Data directory generated by us
input_data_dir = data_dir / 'input_data' # output path
base_file_name = 'seed_123_max100smiles'
### seed for train/val split
random_seed = 123

### Reversed_token_file used to map numbers to string.
reversed_token_map_dir = input_data_dir/ f'REVERSED_TOKENMAP_{base_file_name}.json'

train_dirs = list()
train_dirs.append(train_dir_1)
train_dirs.append(train_dir_2)

train_pickle_dirs = list()
train_pickle_dirs.append(train_pickle_dir_1)
train_pickle_dirs.append(train_pickle_dir_2)

'''generate train_pickle'''
train_csv_dir = data_dir_1 / 'train.csv' #generate train_pickle for DACON(lg dataset)
#train_csv_dir = data_dir_2 / 'train.csv' #generate train_pickle for 1M pubChem